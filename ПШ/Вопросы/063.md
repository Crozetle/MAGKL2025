---
Приоритет:
  - ГЛАВНЫЙ
Direction:
  - "[[ПШ]]"
Discipline: Системы искусственного интеллекта
tags:
  - готово
---
[[062.md|<< Предыдущий вопрос]] | [[064.md|Следующий вопрос >>]]
## Вопрос
Многослойный персептрон. Структура двухслойной сигмоидальной сети.

### Что возможно нужно будет рассказать?
Вопрос фокусируется на расширении базовой модели персептрона к многослойной архитектуре, которая способна решать более сложные задачи, в том числе неразделимые линейно (например, XOR).
#### **Подводные камни:**
- Чётко объяснить, почему однослойный персептрон ограничен (линейная разделимость).
- Показать структуру многослойного персептрона (MLP), в частности двухслойной сети — входной слой, скрытый слой(и), выходной слой.
- Особое внимание уделить скрытому слою — функции и значению.
- Пояснить, почему обычно в MLP используют сигмоидальные функции активации на скрытых слоях.
- Объяснить терминологию: что считается слоем (сколько слоев), почему двухслойная сеть — это минимум для универсального аппроксиматора.
- Желательно привести схему сети с обозначением весов, связей, функций активации.

---
## Ответ
### 2.1 Ограничения однослойного персептрона
#### Основное ограничение
Однослойный персептрон способен корректно классифицировать только те задачи, где классы линейно разделимы — то есть объекты можно разделить с помощью прямой (в 2D), плоскости (в 3D) или гиперплоскости (в многомерном пространстве).

Если данные нельзя разделить одним линейным разделителем, персептрон не сможет найти корректное решение.
#### Пример: задача XOR
- XOR (исключающее ИЛИ) — логическая операция с двумя бинарными входами и одним бинарным выходом.

|Вход X1|Вход X2|Выход XOR|
|---|---|---|
|0|0|0|
|0|1|1|
|1|0|1|
|1|1|0|
Графически точки классов 1 и 0 не разделяются одной прямой:
- Класс 1: (0,1) и (1,0)
- Класс 0: (0,0) и (1,1)

Однослойный персептрон не сможет корректно обучиться классифицировать XOR, так как данные **не являются линейно разделимыми**.

---
### 2.2 Структура многослойного персептрона (MLP)
Многослойный персептрон — это искусственная нейронная сеть, которая содержит **один или несколько скрытых слоев** между входным и выходным слоями. За счёт этого MLP способна моделировать сложные, в том числе нелинейные, зависимости.
#### Общее устройство MLP
- **Входной слой:**  
    Принимает входные данные (признаки). Этот слой не производит вычислений — он только передаёт данные дальше.
- **Скрытые слои:**  
    Один или несколько слоёв, состоящих из нейронов с нелинейными функциями активации (например, сигмоида, tanh, ReLU). Именно здесь происходит сложная обработка и выявление признаков, благодаря чему сеть может решать нелинейные задачи.
- **Выходной слой:**  
    Формирует окончательный ответ сети. В зависимости от задачи (классификация, регрессия) на выходе может быть один или несколько нейронов с подходящей функцией активации (например, сигмоида для бинарной классификации, softmax — для многоклассовой).
#### Почему MLP решает задачу XOR?
- Благодаря **скрытому слою** MLP может создавать **сложные, нелинейные границы** между классами.
- В случае XOR скрытый слой выделяет промежуточные признаки, позволяя выходному слою корректно классифицировать точки.

---
### 2.3 Двухслойная сигмоидальная сеть
#### Использование сигмоидальных функций активации
- В двухслойном MLP обычно применяется **сигмоидальная функция активации** (σ) в нейронах как скрытого слоя, так и выходного слоя.
- Сигмоида преобразует взвешенную сумму входных сигналов в значение в диапазоне (0,1), что удобно для моделирования вероятностей и бинарных решений.

---
## Ссылки
