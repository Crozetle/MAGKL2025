---
Приоритет:
  - ГЛАВНЫЙ
Direction:
  - "[[ПШ]]"
Discipline: Системы искусственного интеллекта
tags:
  - готово
---
[[063.md|<< Предыдущий вопрос]] | [[065.md|Следующий вопрос >>]]
## Вопрос
Алгоритм наискоренного спуска. Алгоритм наискоренного спуска с моментами. Алгоритм обратного распространения ошибки. Алгоритм имитации отжига.

### Что возможно нужно будет рассказать?
Все перечисленные алгоритмы связаны с **оптимизацией параметров нейронных сетей** (в частности — весов), то есть с процессом обучения моделей ИИ.
- **Алгоритм наискоренного спуска (градиентный спуск)** и его модификация — **наискоренный спуск с моментом** — это методы оптимизации, направленные на минимизацию функции потерь. Они служат основой для обучения нейросетей, обеспечивая обновление весов в направлении уменьшения ошибки.
- **Алгоритм обратного распространения ошибки (backpropagation)** — это ключевой метод вычисления градиентов в многослойных нейронных сетях. Без него градиентный спуск просто не применим к глубоким сетям. Обратное распространение — это способ эффективно считать производные ошибки по весам.
- **Алгоритм имитации отжига (simulated annealing)** — это стохастический метод оптимизации, не связанный напрямую с градиентами, но используемый как альтернатива или дополнение к градиентным методам для выхода из локальных минимумов.

Объединение этих алгоритмов в одном вопросе обусловлено тем, что это все **методы оптимизации и обучения**, применяемые для настройки параметров систем искусственного интеллекта, и понимание их вместе даёт целостное представление о механизмах обучения нейросетей и поиске оптимальных решений.

---
## Ответ
| Характеристика                            | Градиентный спуск                | Градиентный спуск с моментом (Momentum, Nesterov)  | Обратное распространение ошибки                | Имитация отжига                                                                        |
| ----------------------------------------- | -------------------------------- | -------------------------------------------------- | ---------------------------------------------- | -------------------------------------------------------------------------------------- |
| **Тип алгоритма**                         | Оптимизация методом градиента    | Оптимизация с учетом накопленного градиента        | Метод вычисления градиентов в нейросетях       | Стохастический метод глобальной оптимизации                                            |
| **Цель**                                  | Минимизация функции ошибки       | Быстрое и устойчивое приближение к минимуму        | Обучение многослойных сетей                    | Поиск глобального минимума, избегая локальных минимумов                                |
| **Обновление весов**                      | На основе градиента              | На основе градиента и предыдущего шага             | Использует вычисленный градиент для обновления | На основе вероятностного принятия новых решений                                        |
| **Особенности**                           | Прост в реализации               | Быстрее сходимость, меньше колебаний               | Позволяет обучать глубокие сети                | Может «перепрыгивать» через локальные минимумы                                         |
| **Скорость сходимости**                   | Медленная, зависит от параметров | Быстрее классического градиентного спуска          | Эффективен благодаря градиентам                | Обычно медленнее, требует много итераций                                               |
| **Риск застревания в локальном минимуме** | Высокий                          | Меньше, но все равно есть                          | Средний, зависит от оптимизатора               | Низкий — предусмотрены «скачки» к лучшим решениям                                      |
| **Применение**                            | Общие задачи оптимизации         | Обучение нейросетей, улучшение градиентных методов | Обучение нейросетей                            | Сложные задачи оптимизации, где градиенты сложно считать или много локальных минимумов |
| **Требования к функции ошибки**           | Дифференцируемость               | Дифференцируемость                                 | Дифференцируемость                             | Необязательно дифференцируемая                                                         |
### Задача для примера
Пусть есть функция ошибки (loss):
$$E(w) = (w - 3)^2$$

Минимум — при $w = 3$. Начинаем с $w_0 = 0$.

Градиент:
$\frac{dE}{dw} = 2(w - 3))$
#### 1. Градиентный спуск (Gradient Descent)
Правило обновления: $$w_{t+1} = w_t - \eta \cdot \frac{dE}{dw_t}$$
Пусть шаг обучения $\eta = 0.1$.

| Итерация | $w_t$​ | Градиент | Обновление $\Delta w$ | Новый $w_{t+1}$​ |
| -------- | ------ | -------- | --------------------- | ---------------- |
| 0        | 0      | -6       | 0.6                   | 0.6              |
| 1        | 0.6    | -4.8     | 0.48                  | 1.08             |
| 2        | 1.08   | -3.84    | 0.384                 | 1.464            |
| 3        | 1.464  | -3.072   | 0.3072                | 1.7712           |
_Параметры постепенно приближаются к 3._
#### 2. Градиентный спуск с моментом (Momentum)
Обновление учитывает предыдущий шаг:$$v_{t+1} = \alpha v_t - \eta \frac{dE}{dw_t}$$$$w_{t+1} = w_t + v_{t+1}$$
Пусть $\alpha = 0.9$, $v_0=0$, $\eta=0.1$.

| Итерация | $w_t$​ | Градиент | $v_{t+1} = 0.9 v_t - 0.1 \cdot grad$ | $w_{t+1} = w_t + v_{t+1}$ |
| -------- | ------ | -------- | ------------------------------------ | ------------------------- |
| 0        | 0      | -6       | 0.6                                  | 0.6                       |
| 1        | 0.6    | -4.8     | 0.9*0.6 + 0.48 = 1.02                | 1.62                      |
| 2        | 1.62   | -2.76    | 0.9*1.02 + 0.276 = 1.164             | 2.784                     |
| 3        | 2.784  | -0.432   | 0.9*1.164 + 0.0432 = 1.087           | 3.871                     |
_Моментум помогает быстрее продвинуться к минимуму, «разгоняя» шаги._
#### 3. Обратное распространение ошибки
Это не самостоятельный алгоритм обновления, а метод вычисления градиентов для многослойной сети. В нашем примере градиент мы уже считаем. Обратное распространение — это способ получить $\frac{dE}{dw}$ в сложных сетях.
#### 4. Имитация отжига (Simulated Annealing)
Имитация отжига — стохастический метод, поэтому приведём схематический пример:
- Начинаем с $w_0=0$, температура $T=1$.
- На каждом шаге генерируем случайное новое значение $w_{new} = w_t + \text{случайное изменение}$.
- Если $E(w_{new}) < E(w_t)$, принимаем $w_{new}$​.
- Иначе принимаем с вероятностью $\exp\left(-\frac{E(w_{new}) - E(w_t)}{T}\right)$.
- Температура $T$ постепенно снижается (охлаждение).

Пример первых шагов:

| Итерация | $w_t$​      | Случайное изменение | $w_{new}$​ | $E(w_t)$ | $E(w_{new})$ | Принят?                                |
| -------- | ----------- | ------------------- | ---------- | -------- | ------------ | -------------------------------------- |
| 0        | 0           | +0.5                | 0.5        | 9        | 6.25         | Да (меньше)                            |
| 1        | 0.5         | -0.3                | 0.2        | 6.25     | 7.84         | Возможно, зависит от TTT и вероятности |
| 2        | 0.5 или 0.2 | ...                 | ...        | ...      | ...          | ...                                    |
_Метод позволяет иногда принимать худшие решения, чтобы избежать застревания в локальном минимуме._

---
## Ссылки
