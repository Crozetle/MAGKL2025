---
Приоритет:
  - ГЛАВНЫЙ
Direction:
  - "[[ПШ]]"
Discipline: Системы искусственного интеллекта
tags:
  - готово
  - сложно
---
[[058.md|<< Предыдущий вопрос]] | [[060.md|Следующий вопрос >>]]
## Вопрос
Метрики оценки качества решения задач классификации и прогнозирования.

### Что возможно нужно будет рассказать?
На первый взгляд, вопрос про **метрики оценки качества** может показаться «узко» техническим — ведь речь идёт о числах и формулах. Но в контексте **Систем искусственного интеллекта (СИИ)** это фундаментальная тема:
- Любая система ИИ (в том числе, обучаемая модель) — это **инструмент принятия решений или прогнозирования**.
- Чтобы понять, насколько эффективно система решает задачи (например, классифицирует объекты или предсказывает значения), нужна **объективная оценка** её работы.
- Метрики — это «язык», на котором ИИ-системы «отчитываются» о своей работоспособности, позволяют сравнивать модели и выбирать лучшие.
- Без грамотной оценки **не возможно контролировать качество ИИ**, улучшать алгоритмы или гарантировать надёжность решений, что особенно важно в реальных приложениях (медицина, финансы, безопасность).
#### **Подводные камни:**
- Не все метрики подходят для всех задач — важно уметь **выбирать метрику под конкретную задачу**.
- Часто метрики взаимосвязаны, и их понимание требует знания базовых статистических понятий (точность, полнота, F-мера, ROC, MSE и др.).
- При описании необходимо чётко различать **метрики для классификации** и **метрики для прогнозирования (регрессии)**.
- Экзаменаторы могут ожидать понимания практического смысла метрик, а не только формул.

---
## Ответ
### 2.1 Общее введение в оценку качества в СИИ
В современных системах искусственного интеллекта (ИИ) и машинного обучения (МО) оценка качества работы модели является ключевым этапом, который влияет на успешность и надёжность решения поставленных задач. Вот почему это важно:
#### Почему важно оценивать качество моделей ИИ?
- **Обеспечение надёжности решений.** Модели ИИ принимают решения или прогнозы, которые могут иметь значительные последствия — от диагностики заболеваний до управления автономными транспортными средствами. Непроверенная или плохо оценённая модель может привести к ошибкам и негативным последствиям.
- **Сравнение и выбор моделей.** Разработка одной модели — лишь первый шаг. Часто создаётся несколько вариантов, отличающихся алгоритмами, параметрами и гиперпараметрами. Метрики качества позволяют объективно сравнить модели и выбрать наиболее подходящую.
- **Оптимизация и улучшение.** Метрики качества служат ориентиром для дальнейшего улучшения моделей — настройки параметров, выбора признаков, методов обучения. Без оценки невозможно понять, какие изменения приводят к улучшению.
- **Предотвращение переобучения и недообучения.** Оценка на тестовых данных позволяет выявить, насколько модель обобщается на новые данные, что крайне важно для практического применения.
- **Демонстрация эффективности.** Для внедрения и использования моделей важно доказать заказчикам и пользователям, что система работает стабильно и эффективно.

---
### 2.2 Метрики для задач классификации
Для оценки качества моделей, решающих задачи классификации, применяются несколько ключевых метрик, каждая из которых отражает разные аспекты работы модели.
#### Основные показатели
- **Матрица ошибок (Confusion Matrix)** — это таблица, которая показывает распределение результатов классификации по четырём категориям:
![[Pasted image 20250811033013.png]]

Отсюда вытекают основные метрики:
- **Точность (Accuracy)** — доля правильных предсказаний среди всех примеров
 $$Accuracy = \frac{TP + TN}{TP + TN + FP + FN}$$​
- **Полнота (Recall, Sensitivity)** — доля правильно найденных положительных примеров среди всех реально положительных
$$Recall = \frac{TP}{TP + FN}$$
- **Точность прогноза (Precision)** — доля правильно предсказанных положительных примеров среди всех, предсказанных положительными
$$Precision = \frac{TP}{TP + FP}$$
- **F-мера (F1-score)** — гармоническое среднее между Precision и Recall, служит балансом между полнотой и точностью

![[Pasted image 20250811035307.png]]
#### ROC-кривая и AUC
ROC-кривая (Receiver Operating Characteristic)** — график зависимости полноты (Recall) от доли ложноположительных срабатываний (False Positive Rate) при различных порогах классификации.

![[Pasted image 20250811035835.png]]
##### Как строится ROC-кривая?
Модель бинарной классификации часто выдаёт не просто метку, а **оценку принадлежности к классу** — вероятность или некоторый скор. Для принятия решения применяется порог: если оценка выше порога — класс «положительный», иначе — «отрицательный».

- При разных значениях порога меняются TP, FP, TN, FN, а значит и FPR и TPR.
- При пороге, близком к 1 (очень строгий критерий), почти никто не классифицируется как положительный → TPR и FPR близки к 0 → точка внизу слева (0,0).
- При пороге, близком к 0 (очень мягкий критерий), почти все классифицируются как положительные → TPR и FPR близки к 1 → точка справа сверху (1,1).

Построив точки (FPR, TPR) для всех порогов, получаем ROC-кривую — выпуклую функцию, идущую из (0,0) в (1,1).
##### Что показывает ROC?
- Кривая ближе к верхнему левому углу — лучше классификатор: высокая полнота при низком числе ложноположительных срабатываний.
- Кривая, близкая к диагонали (от (0,0) до (1,1)), говорит о случайных предсказаниях.

![[Pasted image 20250811034149.png]]

AUC (Area Under Curve) — площадь под ROC-кривой, отражающая общее качество бинарного классификатора. Значение AUC=1 — идеальный классификатор, 0.5 — случайное угадывание.

| Случай            | Описание                                                       | ROC-кривая                                                           | AUC  |
| ----------------- | -------------------------------------------------------------- | -------------------------------------------------------------------- | ---- |
| Идеальный         | Модель всегда правильно определяет классы                      | Кривая быстро поднимается к (0,1) и идёт вдоль левой и верхней грани | 1.0  |
| Случайный         | Модель делает случайные предсказания                           | Кривая — диагональ от (0,0) к (1,1)                                  | 0.5  |
| Плохой (обратный) | Модель систематически путает классы (например, инверсия меток) | Кривая ниже диагонали                                                | <0.5 |

---
### 2.3 Метрики для задач прогнозирования (регрессии)
В отличие от классификации, где результат — дискретный класс, в регрессии модель выдаёт численное значение, которое должно быть как можно ближе к реальному. Для оценки этого качества используют несколько метрик, которые измеряют ошибки между предсказанными и истинными значениями.
#### Основные метрики регрессии
##### 1. **Средняя квадратичная ошибка (MSE, Mean Squared Error)**
$$MSE = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2$$
Где:
- $y_i$ — истинное значение,
- $\hat{y}_i$ — предсказанное моделью,
- $n$ — число наблюдений.

**Что показывает:**  
Усреднённую квадратуру отклонений предсказаний от реальных значений. Квадрат ошибки усиливает влияние больших отклонений (ошибок), поэтому MSE особенно чувствительна к выбросам.
##### 2. **Средняя абсолютная ошибка (MAE, Mean Absolute Error)**
$$MAE = \frac{1}{n} \sum_{i=1}^n |y_i - \hat{y}_i|$$
**Что показывает:**  
Среднее абсолютное отклонение. Более «робастна» к выбросам, чем MSE, так как не возводит ошибку в квадрат.
##### 3. **Root Mean Squared Error (RMSE)**
$$RMSE = \sqrt{MSE} = \sqrt{\frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2}$$
**Что показывает:**  
Корень из средней квадратичной ошибки возвращает ошибку в тех же единицах измерения, что и исходные данные, что облегчает интерпретацию. Чувствительна к крупным ошибкам.
##### 4. **Коэффициент детерминации (R²)**
$$R^2 = 1 - \frac{\sum_{i=1}^n (y_i - \hat{y}_i)^2}{\sum_{i=1}^n (y_i - \bar{y})^2}$$​Где $\bar{y}$ — среднее значение истинных наблюдений.

**Что показывает:**  
Долю дисперсии истинных данных, объяснённую моделью.
- $R^2 = 1$ — идеальная модель,
- $R^2 = 0$ — модель не лучше среднего,
- $R^2 < 0$ — модель хуже простого среднего значения.
#### Итог
- **MSE, RMSE, MAE** — показывают величину ошибки, чем меньше — тем лучше.
- **MSE и RMSE** делают акцент на больших ошибках из-за квадратичного компонента.
- **MAE** более устойчив к выбросам, даёт прямое среднее отклонение.
- **R²** даёт относительную оценку, насколько модель объясняет данные.

---
## Ссылки