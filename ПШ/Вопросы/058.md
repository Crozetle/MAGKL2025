---
Приоритет:
  - ГЛАВНЫЙ
Direction:
  - "[[ПШ]]"
Discipline: Системы искусственного интеллекта
tags:
  - готово
---
[[057.md|<< Предыдущий вопрос]] | [[059.md|Следующий вопрос >>]]
## Вопрос
Искусственный интеллект. Машинное обучение. Виды. Способы и задачи машинного обучения.

### Что возможно нужно будет рассказать?
Вопрос охватывает фундаментальные понятия: что такое искусственный интеллект (ИИ) и машинное обучение (МО), а также классификацию видов и способов МО и ключевые задачи, которые решаются с помощью этих методов.

**Подводные камни:**
- Нужно чётко различать понятия ИИ и МО (не путать их как синонимы).
- Пояснить основные направления и типы МО (например, обучение с учителем, без учителя, с подкреплением).
- Важно уметь связать виды МО с конкретными задачами (например, классификация, регрессия, кластеризация).
- Рассмотреть способы обучения (например, статистические методы, нейросети, методы ближайших соседей) с краткой характеристикой.
- Не забыть, что экзаменаторы могут ожидать не только формального определения, но и практическую иллюстрацию (например, где применяется каждый вид обучения).

---
## Ответ
### 2.1 Искусственный интеллект (ИИ)
Искусственный интеллект (ИИ) — это область компьютерных наук, занимающаяся созданием систем, способных выполнять задачи, которые традиционно требуют человеческого интеллекта. К таким задачам относятся способность рассуждать, принимать решения, понимать и обрабатывать естественный язык, распознавать образы, а также учиться на опыте. Основная цель ИИ — имитация человеческих когнитивных функций для автоматизации и оптимизации интеллектуальной деятельности.

---
### 2.2 Машинное обучение (МО)
Машинное обучение (МО) является ключевым направлением в ИИ, сфокусированным на создании алгоритмов, которые позволяют системам самостоятельно выявлять закономерности и делать выводы на основе данных без явного программирования каждой конкретной задачи. В отличие от классического программирования, где программист прописывает точные правила и логику, МО использует обучающие данные для формирования модели, способной обобщать и принимать решения на новых данных.

| Компонент         | Описание                                                                                                                      |
| ----------------- | ----------------------------------------------------------------------------------------------------------------------------- |
| Данные            | Набор информации (входных примеров), на основе которых модель учится выявлять закономерности.                                 |
| Модель            | Формальное представление зависимости между входными данными и выходными результатами, которое обучается.                      |
| Алгоритм обучения | Метод, с помощью которого происходит настройка модели на данных с целью минимизации ошибки и повышения качества предсказаний. |
Таким образом, МО позволяет создавать адаптивные системы, способные к улучшению своих результатов по мере поступления новых данных, что является одной из ключевых характеристик современных систем искусственного интеллекта.

---
### 2.3 Виды машинного обучения
В машинном обучении выделяют три основных вида, каждый из которых решает определённый класс задач и использует свой подход к обучению модели.

**1. Обучение с учителем (supervised learning)** — это метод, при котором модель обучается на размеченных данных, то есть каждый входной пример сопровождается правильным ответом (меткой). Цель — научиться предсказывать эти метки для новых, ранее не встречавшихся данных. В рамках обучения с учителем выделяют две ключевые задачи:
- **Классификация** — задача отнесения объектов к заранее определённым категориям. Например, распознавание рукописных цифр, где модель должна определить, какая цифра изображена.
- **Регрессия** — задача предсказания непрерывного значения. Пример — прогнозирование цены на жильё по параметрам объекта.

**2. Обучение без учителя (unsupervised learning)** — подход, при котором модель работает с неразмеченными данными, без заранее заданных ответов. Основная задача — выявление скрытых закономерностей или структур в данных. Основные методы:
- **Кластеризация** — группировка объектов по схожести, например, сегментация клиентов по покупательскому поведению.
- Выявление ассоциативных правил и других скрытых паттернов.

**3. Обучение с подкреплением (reinforcement learning)** — метод обучения через взаимодействие агента с окружающей средой, где агент получает обратную связь в виде наград или штрафов. Цель — разработать стратегию действий, максимизирующую суммарную награду в долгосрочной перспективе. Примеры: обучение игре в шахматы, управление роботами.

---
### 2.4 Способы и методы машинного обучения
В машинном обучении существует множество способов и методов, каждый из которых обладает своими особенностями, преимуществами и сферами применения. Рассмотрим ключевые из них:

**1. Статистические методы**  
Основаны на математическом анализе данных и моделировании зависимости между переменными. Например, **линейная регрессия** моделирует линейную связь для задач прогнозирования, а **наивный Байес** — вероятностный классификатор, основанный на теореме Байеса с предположением о независимости признаков. Эти методы хорошо работают на небольших и средних объёмах данных и позволяют легко интерпретировать результаты.

**Задача:** Прогнозирование цены квартиры по площади, количеству комнат и этажу.  
**Причина выбора:** Цену можно примерно описать линейной зависимостью от параметров жилья, данные числовые и легко интерпретируемые. Линейная регрессия проста, быстро обучается, и результаты легко объяснить заказчику.  
**Почему другие методы не подходят:** Нейронные сети или SVM избыточны для такой простой задачи и требуют больше вычислительных ресурсов. k-NN плохо масштабируется при большом количестве данных, а деревья решений могут переобучиться на шумных данных.

**2. Нейронные сети**  
Модели, вдохновлённые работой биологических нейронов, способны моделировать сложные нелинейные зависимости. Они универсальны и применяются для задач классификации, регрессии, обработки изображений и текста.

**3. Метод ближайших соседей (k-NN)**  
Простой алгоритм, основанный на предположении, что объекты с похожими признаками имеют похожие метки. Классификация или регрессия выполняется на основе анализа k ближайших объектов. Метод не требует этапа обучения, однако страдает от высокой вычислительной сложности при больших данных и чувствителен к размерности.

**Задача:** Рекомендация фильмов на основе предпочтений пользователя и рейтингов похожих пользователей.  
**Причина выбора:** k-NN легко применим, когда понятна близость объектов (например, по жанрам и оценкам). Нет необходимости обучать сложные модели, система быстро адаптируется к новым пользователям и фильмам.  
**Почему другие методы не подходят:** Линейная регрессия не подходит, так как задача не линейна и имеет сложные зависимости. Нейронные сети требуют много данных и вычислений. Деревья решений могут работать, но k-NN более интуитивен в данном случае.

**4. Деревья решений**  
Модель, которая строится в виде дерева с условиями на внутренних узлах и решениями на листьях. Хорошо интерпретируемы, работают с числовыми и категориальными признаками. Часто используются в задачах, где важна прозрачность принятия решений.

**Задача:** Кредитный скоринг — определить, выдавать ли кредит на основе финансовых и персональных данных клиента (возраст, доход, кредитная история и т.д.).  
**Причина выбора:** Деревья дают прозрачные правила, понятные сотрудникам банка и клиентам. Их легко интерпретировать и объяснить решение. Модель хорошо работает с разнородными признаками (числовыми и категориальными).  
**Почему другие методы не подходят:** Нейронные сети менее интерпретируемы и требуют больше времени на обучение. k-NN тяжело объяснить бизнесу, а SVM сложны для понимания и настройки в этой задаче.

**5. Машина опорных векторов (SVM)**  
Метод, который находит гиперплоскость, максимально разделяющую классы, эффективно работает в высокоразмерных пространствах. С помощью ядровых функций можно решать нелинейные задачи. Требует настройки параметров и хорошо подходит для классификации и регрессии с учителем.

**Задача:** Классификация изображений для распознавания рукописных цифр (например, цифр в почтовых индексах).  
**Причина выбора:** SVM хорошо справляется с высокоразмерными данными (изображениями), эффективно выделяет границы между классами и устойчив к переобучению. Использование ядровых функций позволяет обрабатывать сложные нелинейные структуры.  
**Почему другие методы не подходят:** Линейная регрессия не подходит из-за нелинейности задачи. k-NN медленен при большом объёме данных. Деревья решений могут переобучаться и хуже работать с большим количеством признаков.

**6. Методы кластеризации (обучение без учителя)**  
В отличие от перечисленных выше методов с учителем, методы кластеризации работают с неразмеченными данными и предназначены для выявления скрытых групп и структур в данных. Классическими примерами являются:
- **k-means** — алгоритм, который разбивает данные на k кластеров, минимизируя внутрикластерную вариацию.
- **Иерархическая кластеризация** — формирует дерево кластеров, объединяя или разбивая группы на основе меры сходства.

Эти методы широко применяются для предварительного анализа данных, сегментации пользователей или объектов, выявления паттернов.

|Метод|Тип обучения|Особенности|Сферы применения|
|---|---|---|---|
|Линейная регрессия|С учителем|Простая, интерпретируемая модель|Прогнозирование, эконометрика|
|Наивный Байес|С учителем|Быстрый, устойчивый к шуму|Текстовая классификация, фильтрация спама|
|Нейронные сети|С учителем|Моделирование сложных зависимостей|Обработка изображений, речи, текста|
|Метод ближайших соседей (k-NN)|С учителем|Простота, без обучения|Рекомендации, биометрия|
|Деревья решений|С учителем|Интерпретируемость, работа с разнородными данными|Маркетинг, медицина, кредитование|
|Машина опорных векторов (SVM)|С учителем|Максимизация зазора, работа с высокими размерностями|Биометрия, распознавание образов|
|Методы кластеризации (k-means, иерархическая)|Без учителя|Выявление групп без меток|Сегментация пользователей, анализ данных|

---
### 2.5 Задачи машинного обучения
#### 1. Классификация
Задача классификации состоит в том, чтобы отнести входной объект к одному из заранее определённых классов. Например, распознавание спама в электронной почте (спам/не спам), определение болезни по медицинским признакам (болен/здоров), или распознавание рукописных цифр.  
Методы решения: логистическая регрессия, деревья решений, SVM, нейронные сети, k-NN.  
Классификация — классическая задача обучения с учителем, требующая размеченных данных.
#### 2. Регрессия
Регрессия направлена на прогнозирование числового значения на основе входных данных. Например, прогнозирование цены недвижимости по параметрам, предсказание температуры на завтра, оценка уровня продаж.  
Используются методы линейной и полиномиальной регрессии, нейронные сети, SVM с регрессионной функцией.  
Отличие от классификации — в выходных данных — они непрерывны, а не дискретны.
#### 3. Кластеризация
Это задача обучения без учителя, где нет заранее заданных меток. Цель — группировка объектов в кластеры по сходству.  
Примеры: сегментация клиентов по поведению, группировка новостей по тематике, выделение типов пользователей на сайте.  
Основные методы — k-means, иерархическая кластеризация, DBSCAN.
#### 4. Снижение размерности
Часто данные имеют большое число признаков, что затрудняет анализ и обучение. Снижение размерности позволяет упростить данные, выделив наиболее информативные признаки.  
Один из классических методов — **анализ главных компонент (PCA)** — преобразует исходные признаки в новый набор, упорядоченный по степени объяснения дисперсии.  
Применяется для визуализации, предварительной обработки данных, устранения шумов.
#### 5. Рекомендательные системы
Цель — предложить пользователю товары, фильмы, книги, которые ему наиболее интересны на основе его предыдущих действий и предпочтений других пользователей.  
Реализуются с помощью методов коллаборативной фильтрации, контентного анализа, гибридных подходов, а также методов машинного обучения, например, k-NN, матричной факторизации и нейронных сетей.
#### 6. Другие задачи
- **Обнаружение аномалий** — выявление редких или необычных объектов, например, мошеннических операций в банковских данных или неисправностей в промышленном оборудовании.
- **Генерация данных** — создание новых данных, например, генерация текста или изображений с помощью генеративных нейронных сетей.

---
### 2.6 Рекомендации по примерам
|Вид машинного обучения|Основные задачи|Основные методы|Краткое описание задач|
|---|---|---|---|
|Обучение с учителем|Классификация, регрессия|Линейная регрессия, SVM, деревья решений, нейронные сети, k-NN|Модель обучается на размеченных данных, предсказывает метки или значения|
|Обучение без учителя|Кластеризация, снижение размерности|k-means, иерархическая кластеризация, PCA|Выявление скрытой структуры, упрощение данных без меток|
|Обучение с подкреплением|Оптимизация последовательности действий|Q-обучение, Deep Q-Networks|Модель обучается через взаимодействие с окружением и получение наград|
```c
Искусственный интеллект (ИИ)
    ↓
Машинное обучение (МО) — одно из направлений ИИ
    ↓
Виды МО:
    - Обучение с учителем
    - Обучение без учителя
    - Обучение с подкреплением
    ↓
Задачи МО:
    - Классификация
    - Регрессия
    - Кластеризация
    - Снижение размерности
    - Рекомендационные системы
    - Обнаружение аномалий
```
#### Пример псевдокод для k-NN)
```python
# Дано: обучающая выборка train_data с признаками и метками, тестовый объект test_point

def euclidean_distance(a, b):
    return sqrt(sum((a_i - b_i)**2 for a_i, b_i in zip(a, b)))

def k_nearest_neighbors(train_data, test_point, k=3):
    # Вычисляем расстояния от test_point до всех точек обучающей выборки
    distances = []
    for features, label in train_data:
        dist = euclidean_distance(features, test_point)
        distances.append((dist, label))
    # Сортируем по расстоянию
    distances.sort(key=lambda x: x[0])
    # Берём k ближайших соседей
    neighbors = distances[:k]
    # Подсчитываем метки среди соседей
    votes = {}
    for _, label in neighbors:
        votes[label] = votes.get(label, 0) + 1
    # Выбираем наиболее частую метку
    predicted_label = max(votes, key=votes.get)
    return predicted_label

# Пример использования:
train_data = [([1.0, 2.0], 'A'), ([1.5, 1.8], 'A'), ([5.0, 8.0], 'B')]
test_point = [1.2, 1.9]
print(k_nearest_neighbors(train_data, test_point))
```

---
## Ссылки
